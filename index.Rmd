---
title: "SDS 293: Modeling for Machine Learning"
author: "Albert Y. Kim"
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    df_print: kable
    includes:
      in_header: "favicon.html"
---

<style>
h1{font-weight: 400;}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo=TRUE, 
  message=FALSE, 
  warning=FALSE, 
  eval=FALSE, 
  fig.width=16/2, 
  fig.height=9/2
)
library(tidyverse)
library(broom)
library(knitr)
library(modelr)
library(lubridate)
library(forcats)
library(nycflights13)
library(patchwork)
library(okcupiddata)
# devtools::install_github("hadley/emo")
library(emo)

# Set seed value of random number generator to get "replicable" random numbers.
set.seed(76)
```

```{r, eval=FALSE, echo=FALSE}
# Run this separately to have slide output:
rmarkdown::render("index.Rmd", output_format = c("ioslides_presentation"), output_file = "slides.html")
```

<style>
h1{font-weight: 400;}
</style>



***



# Schedule 

<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vToPV6gfDlIq5ni1qezMcPy3ZdyIN1MtSSKZ3GABeBvf9LYu3_1XE7DOEQh4Dg02bKG5YF0XpSFO_-B/pubhtml?gid=2021662517&amp;single=true&amp;widget=true&amp;headers=false" width="100%" height="775"></iframe>

<!--
{target="_blank"}
-->



***

# Lec 11: Wed 2/19

## Announcements

* 


## Topics

1. Recap of Lec10: Idea of validation sets: fit/train model to one set of data, but evaluate predictive performance on another set of data. Recall Lec01 "What is Machine Learning?" [slide 26](static/what_is_ML.pdf#page=27){target="_blank"} on training a self-driving car versus evaluating it's performance.
1. Create a table comparing 3 types of RMSLE scores for two `cp` values: `cp=0` & `cp=1` (i.e. a less complex tree)
1. Comparing performance of underfit vs overfit models as a function of model complexity. See Lec01 "What is Machine Learning?" [slide 27](static/what_is_ML.pdf#page=27){target="_blank"}.




***



# Lec 10: Mon 2/17

## Announcements

* Sit next to your PS3 partner
* Problem sets:
    + PS3 posted
    + I'm still coordinating with grader. You'll get PS1 scores shortly.
    + Great common student question: "Why are randomizing groups? Why can't we just pick our own?"


## Topics

1. $\log$-transformations (you'll be doing this in PS3)
    + Problem: many students who used `OverallQual` as a predictor, ended up with a negative prediction $\widehat{y}$ = $\hat{\text{SalePrice}}$
    + Solution: Transforming the outcome variable space, then fitting your model, then predicting, then returning to the original variable space
1. Recap of underfitting vs overfitting:  
![](static/images/ML_Flashcards/Underfitting_web.png){ width=50% }![](static/images/ML_Flashcards/Overfitting_web.png){ width=50% } 
1. Why is overfitting a problem?
    + Solutions to Lec09 Exercise are posted on Slack: showing the consequences on RMSLE of making predictions on separate `test` data using a model that is HELLA overfit to the `training` data using `cp = 0`.
    + What are validation sets? Train your model on one set of data, but evaluate your predictions on a separate set of data. Recall Lec01 "What is Machine Learning?" [slide 26](static/what_is_ML.pdf#page=27){target="_blank"} on training a self-driving car versus evaluating it's performance.



***



# Lec 09: Fri 2/14

## Announcements

1. I'm almost finished PS3. A large part of it will involve fitting a CART model to the same house prices data as in PS2.
1. Check out [Machine Learning Flashcards](https://gumroad.com/l/machinelearningflashcards){target="_blank"} posted on Slack in `#general`
1. Open Slack and please join the `#questions` channel. Ask all non-private questions here.

## Topics

1. PS2 recap
    + Two TODO's for this PS: 1) compute RMSLE and 2) submit Kaggle predictions. Where do I use `train` and where do I use `test`?
    + RMSE vs RMSLE. What's the difference? Recall from Lec04 our [discussion on orders of magnitude](https://moderndive.com/A-appendixA.html#appendix-log10-transformations){target="_blank"}.
1. CART wrap-up
    a) Open MassMutual RStudio Project -> `CART.Rmd` -> Explain $\widehat{p}_{mk}$, in particular how it plays into "Gini Index".  
    ![](static/images/ML_Flashcards/Gini_Index_web.png){ width=50% }
    a) What does the equation become when $y$ is numerical
    a) Tie-in CART "complexity parameter" $\alpha$ with Lec01 "What is Machine Learning?" [slide 20](static/what_is_ML.pdf#page=20){target="_blank"} on under vs overfit models.
1. Two possible model outcomes: Underfitting vs overfitting:  
![](static/images/ML_Flashcards/Underfitting_web.png){ width=50% }![](static/images/ML_Flashcards/Overfitting_web.png){ width=50% }  
1. Open MassMutual RStudio Project -> `coding.Rmd` -> `# Wednesday, July 24 2019` -> `Demonstration of overfitting`
    a) `model_CART_3` corresponds to a HELLA overfit model. i.e. it doesn't generalize.
    b) Exercise: Fit the same model but to only half the data, predict on the other half.  
    ![](static/images/validation_set.png){ width=75% }  



***



# Lec 08: Wed 2/12

## Announcements

* None


## Topics

### Special cases

1. How do I do binary splits on categorical predictors that have been *one-hot encoded*. Note: many statistical software packages will do this automatically for you.  
![](static/images/ML_Flashcards/One-Hot_Encoding_web.png){ width=50% }
1. Works for both types of outcomes $y$: numerical & categorical. Show code


### What does the complexity parameter do?

Today's chalk talk on CART is based on the Tuesday PM topics in the [MassMutual Google Doc](https://docs.google.com/document/d/1kBl8ivTeNyVfbV0gvXjBpwnlRWXvZkKuSe0SMTjFB38/edit#heading=h.4llig2jamgry){target="_blank"}. 

Open the MassMutual RStudio Project -> `CART.Rmd` Shiny app. (Note: after you install the necessary packages, this should knit.) 

1. On what variable and where along selected variable do the splits occur?
1. How many splits, i.e. how far do we "grow" the tree? Or in other words, how *complex* do we make the tree?



***




# Lec 07: Mon 2/10

## Announcements

* Open 293 GitHub organization -> look at PS2


## Topics

Today's chalk talk on CART is based on the Tuesday PM topics in the [MassMutual Google Doc](https://docs.google.com/document/d/1kBl8ivTeNyVfbV0gvXjBpwnlRWXvZkKuSe0SMTjFB38/edit#heading=h.4llig2jamgry){target="_blank"}. 
![](static/images/ML_Flashcards/Decision_Trees_web.png){ width=50% }


Open the MassMutual RStudio Project:
  
**First:** Based on `coding.Rmd` -> Tuesday -> `iris` dataset. (Note: You might have to do a little debugging to get this to knit, like setting `eval = TRUE` for all code blocks.)

1. What is classification?
1. How do I interpret trees? Binary splits on predictor variables
1. Go over code for CART.



***



# Lec 06: Fri 2/7

## Announcements

* PS1
    + Sit next to your PS1 teammate for today's in-class exercise
    + Albert will go over some PS1 highlights
* PS2: Groups posted, but do not clone PS2 repos until I say so. It will involve:
    1. Creating a model with 3 numerical & 3 categorical variables
    1. Applying your fitted model to the training data, comparing $y$ and $\hat{y}$, and computing RMLSE using `mutate()`
* Open [syllabus](syllabus.html): office hours calendar posted on top. 
* If you haven't already, please change your default GitHub profile picture. It doesn't have to be a picture of you, but please put an image. This will help me quickly identify who's who. 


## Topics

### 1. Lec05 Recap

Exercise from Lec05 -> MassMutual RStudio Project -> Tuesday -> Exercise: Submit Kaggle predictions using linear regression model.

1. What issues did you encounter?
1. What variables did you use? Did you not use? 
    
    
### 2. Git merge conflicts

In-class exercise. The screencast is posted [here](https://www.loom.com/share/83499c93430c4ff6a9f3d08478606a88){target="_blank"}.

1. Open:
    + RStudio -> PS1 RStudio Project
    + GitHub organization for this class (click octocat button on top)
1. Both of you, "pull" your repo to update it
1. Both of you, edit *the same line* in `README.md`, but write something different.
1. Both of you, commit your change but do not push it yet.
1. Only one of you (call them person A), push your commit.
1. Person B: Try to push your commit. You won't be able to because you have a *merge conflict*. You need to resolve it.
1. Person B: "Pull" your repo to bring in the merge conflict.
1. Both of you, resolve the merge conflict together.


### 3. Ethical discussion

The `iris` dataset has historically been one of the most widely used datasets in statistics, first collected by Ronald A. Fisher. Type `?iris` in the console and look at "Source." While Fisher has done a lot to advance the field, some of his views were IMO [problematic](https://njoselson.github.io/Fisher-Pearson/){target="_blank"}.


### 4. Classification & Regression Trees

What are classification and regression trees? Here is one example from the [New York Times](https://www.nytimes.com/interactive/2019/08/08/opinion/sunday/party-polarization-quiz.html){target="_blank"}. Note: Smith students can get free access to the New York Times and Wall Street Journal via [Smith Libraries](https://libraries.smith.edu/news/2019/09/new-online-access-new-york-times-and-wall-street-journal){target="_blank"}.



***



# Lec 05: Wed 2/5

## Announcements

* Added two notes to [PS1](PS.html#PS1)


## Topics

* Multiple regression
* In MassMutual RStudio Project -> Tuesday -> Kaggle -> Exercise on Kaggle submission.



***



# Lec 04: Mon 2/3

## Announcements

* For this week's lectures, sit with your PS1 teammate. The groups are posted on Slack under `#general`
* Lecture policies
    + You don't need to inform me about occasional absenses, but please give your teammate a heads up as a curtesy.
    + Please do not leave in the middle lecture, unless you get prior approval from me, as this can be very distracting. After you get prior approval, please sit near the exit.
* [PS1 is now ready!](PS.html#PS1)


## What is a minimally viable product?

When building a product, in my opinion (IMO):

* **Don't**: Try to do everything completely and perfectly from the beginning. This leads perfectionism, which leads to procrastination and "analysis paralysis."
* **Do**: Start by finishing a [minimially viable product](https://www.interaction-design.org/literature/article/minimum-viable-product-mvp-and-design-balancing-risk-to-gain-reward){target="_blank"} ASAP!

<center>
![](static/images/MVP.png){ width=525px }
</center>

Once you're done your MVP, iterate and improve by slowly adding complexity that work:

<center>
![](static/images/MVP2.png){ width=525px }
</center>

In other words:

* [Done is better than perfect](https://lifehacker.com/done-is-better-than-perfect-5870379){target="_blank"}
* [Don't let the perfect be the enemy of the good](https://www.huffpost.com/entry/dont-let-the-perfect-be-t_b_158673){target="_blank"}
* [Think big, start small](https://www.forbes.com/sites/chunkamui/2016/01/03/6-words/#15457a371a3b){target="_blank"}


## Topics

* In-class demo
* Open `MassMutual` RStudio Project -> `coding.Rmd` -> `# Tuesday, July 23 2019` -> `## Gentle Introduction to Kaggle Competitions`. Discussion on:
    + "Minimally viable product" model $\widehat{y} = \overline{y}$ for *all* houses.
    + log10-transformations:
        * A [discussion on orders of magnitude](https://moderndive.com/A-appendixA.html#appendix-log10-transformations){target="_blank"} as well as another [house prices example](https://moderndive.netlify.com/11-thinking-with-data.html#house-prices-EDA-I){target="_blank"} of a log10-transformation.
        * [Powers of Ten](https://youtu.be/0fKBhvDjuy0?t=40){target="_blank"} movie by Charles and Ray Eames.



***



# Lec 03: Fri 1/31

## Announcements

* GitHub organization for this class:
    + Access it by clicking the "octocat" icon on the top left of this page
    + Ensure you are a member (I sent an email invite yesterday)
* GitHub profile. Think of it as an extension of your resume. I highly encourage, but do not require, you to:
    + Post your full name
    + Post your affiliation
    + Post a public-facing profile picture (it doesn't have to be an image of you, it can be any picture).
    + Please don't change your GitHub ID's mid-semester!
* FYI: GitHub is not without [controversy](https://techcrunch.com/2019/11/13/github-faces-more-resignations-in-light-of-ice-contract/){target="_blank"}

## Topics

GitHub has many definitions that are unforunately not straight forward. Using [`fivethirtyeight`](https://github.com/rudeboybert/fivethirtyeight){target="_blank"} R package as an example.

* Git vs GitHub
* Local vs remote
* Repos & `README.md` files as cover pages
* Cloning a repo locally (which in our case correspond to RStudio Projects). Ex: Big green "Clone or download" button on top right.
* Commit/push and pull. Commits as units of change. Ex: Click "commits" tab on top left (currently at 523 commits)
* Branches: `master` branch is what you see. Ex: Click "Branch" button on top left 
* Making contributions to `master`
    + When on the inside: Create a new branch, make edits in branch, then make pull request
    + When on the outside: Fork the repo (similar to creating a branch), make edits in your forked copye of repo, then make pull request
    + Ex: Click on Insights tab on top right -> Network -> Scroll to earlier dates. 
* Learning git has a steep learning curve. This is normal:
    + [xkcd](https://xkcd.com/1597/){target="_blank"}
    + [Oh shit, git!](https://gumroad.com/l/oh-shit-git){target="_blank"}
    + In this class: I'll (gently) force you to practice merge conflicts




***



# Lec 02: Wed 1/29

## Announcements

* On Sun 1/26 I sent an email including links to join Slack and a Intro Survey Google Form. If you did not receive this email, please come see me after class.
* Syllabus [posted](syllabus.html)


## Topics

* In [MassMutual Google Doc](https://docs.google.com/document/d/1kBl8ivTeNyVfbV0gvXjBpwnlRWXvZkKuSe0SMTjFB38/edit#heading=h.4llig2jamgry){target="_blank"}: Tuesday AM.



***



# Lec 01: Mon 1/27

## Announcements


## Topics

* Went over "What is Machine Learning?" [slides](static/what_is_ML.pdf){target="_blank"}.
