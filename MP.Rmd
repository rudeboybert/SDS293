---
title: "Mini-Projects"
output:
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE, 
                      cache=TRUE, fig.width=16/2, fig.height=9/2)
# Set seed value of random number generator to get "replicable" random numbers.
# Why 76? Because of https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

<style>
h1{font-weight: 400;}
</style>


<!--
{target="_blank"}
-->


***


# Mini-project 1 {#MP1}

## Administrative notes

* **Executive summary**: You will be making a submission to the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques){target="_blank"} Kaggle competition based on a fitted spline model. The competition's score for leaderboard purposes is the "root mean squared logarithmic error" (RMSLE).
* Due Wednesday 2/13 5pm on Moodle.
* You will be given time to work on MP1 in class on Wednesday 2/13.
* Groups: Posted on [Moodle](https://moodle.smith.edu/course/view.php?id=33108){target="_blank"}. Whoever member \#1 is will be the group leader.  
Ex: Group \#1's leader is LQ.


## Working on your project {#MP1-working}

* Download the `MP1.zip` archive file containing the MP1 RStudio Project by clicking <a href="static/MP1.zip" download>here</a>. 
* **Windows users**: Be sure to "extract" the contents of `MP1.zip` to a folder on your machine.
* Whenever working on MP1, be sure to be in "RStudio Project mode" by looking for the RStudio Project icon:  
![](static/images/rstudio_projects.png){ width=100px }
* Get in "RStudio Project mode" either by:
    1. Clicking the `MP1.Rproj` file
    1. Selecting `MP1` from the drop-down menu of RStudio Projects in the top right of RStudio
* Knit the `MP1.Rmd` file and read over everything once.
* Whenever you're not working on your project, click the RStudio Project icon in the top right of RStudio and select "Close Project".
* **Added on Mon 2/11**: It is your responsibility to stay on top of all messages sent in the `#mp1` channel in Slack.
* **Added on Mon 2/11**: Feel free to use external sources, but please cite them using R Markdown footnotes. For example adding `^[This is my [source](https://www.smith.edu/)]` at the end of a sentence in R Markdown will yield: ^[This is my [source](https://www.smith.edu/)]


## What to submit

* **Group leader only**: Submit a `MP1_Group_XX.zip` archive file of **all** the contents of your `MP1` RStudio Project folder.  
Ex: Group \#1's leader LQ will submit a single file `MP1_Group_01.zip` on Moodle.
* **Both group members**: Complete the following peer evaluation [Google Form](https://docs.google.com/forms/d/e/1FAIpQLSc0F4X5s01LEfQ_-1ZJRnzL_jH6K9hnyjJVwLnfKq7tcqGo-A/viewform){target="_blank"}.  
Ex: Both Group \#1's members LQ and EN must complete the Google Form to receive full credit.


## Grading

1. **Minimally viable product:** Grade: 8/10. Fit a splines model with an arbitrarily chosen numerical predictor variable $x$ and an arbitrarily chosen degrees of freedom $df$. Using this model make a submission to Kaggle that returns a valid $\text{RMLSE}$ score. Also:
    + Your `MP1.Rmd` R Markdown "knits" correctly. In other words, an `.html` report gets created with no errors.
    + Complete the exploratory data analysis where all visualizations are as "stand-alone" as possible by having informative labels and titles.
    + Remove all superfluous non-informative output from your report that only makes it more painful/tiresome to read.
    + Both group members submit their peer evaluations. No extensions will be granted.
1. **Due diligence:** Grade: 8.5/10. Explore choices degrees of freedom $df$ in some non-arbitrary fashion. This could mean many things, including:
    + Explicitly compare the $\text{RMLSE}$ for two values of $df$.
    + Implement the validation set prediction framework you saw in [Chapter 4](https://campus.datacamp.com/courses/modeling-with-data-in-the-tidyverse/model-assessment-and-selection?ex=10){target="_blank"} of the Modeling with Data in the tidyverse DataCamp course.
1. **Reaching for the stars:** Grade: 9/10. Fully implement a crossvalidation scheme from scratch in order to:
    + Find the optimal "model complexity". In other words, find the optimal degrees of freedom $df^*$ in a systematic fashion.
    + Get a good estimate $\widehat{\text{RMLSE}}$ of the $\text{RMLSE}$ that Kaggle will return for your submission.
1. **Point of diminishing returns:** Grade: 9.5/10. Create a visualization like in [Lec01 slides \#36](http://rudeboybert.rbind.io/talk/2019-01-13-Williams.pdf#page=36){target="_blank"} that shows
    + The relationship between "model complexity" set by $df$ and $\text{RMLSE}$ for both the training and test data.
    + That the optimal $df^*$ is the "just right" balance point between underfitting and overfitting.
1. **Polishing the cannonball:** Grade: 10/10. Try to get the highest Kaggle score in the class!


## Suggestions

**Always start simple!** Don't try to do things perfectly from the very beginning, but instead follow the [Build, Measure, Learn](http://theleanstartup.com/principles){target="_blank"} cycle espoused by certain individuals in the startup world:

1. **Build**: Start by building a [minimially viable product](https://www.forbes.com/sites/quora/2018/02/27/what-is-a-minimum-viable-product-and-why-do-companies-need-them/#178bd8a2382c){target="_blank"}. 
1. **Measure**: Collect feedback and perform assessments on your product.
1. **Learn**: Learn from this data to figure out what improvements can be made, what complexity can be added, what should be removed in the next version of your product.

Repeat the above and slowly **iterate** to perfection while keeping in mind that **done is better than perfect.** 

<center>
![](static/images/BML.png){ width=275px } ![](static/images/MVP.png){ width=525px }
</center>


## One possible approach {#MP1-discussion}

There is no one single "right "solution to this MP1, but here is <a href="static/MP1_albert_MVP.Rmd" download>one possible approach</a> (copy this `.Rmd` file to your MP1 RStudio Project folder).


***


# Mini-project 2 {#MP2}

## Administrative notes

* **Executive summary**: You will be making a submission to the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques){target="_blank"} Kaggle competition based on a fitted ~~spline~~ multiple regression model. The competition's score for leaderboard purposes is the "root mean squared logarithmic error" (RMSLE).
* **Due Wednesday 3/6 5pm on Moodle**. 
* You will be given time to work on MP2 in class on Monday 3/4 and Wednesday 3/6.
* Groups: You must work with a different partner than MP1
    + **If you already have a group**: Designate a team leader and have them fill out this [Google Sheet](https://docs.google.com/spreadsheets/d/1YRlmq4pvrzmtq0iUha4uCwg2Xwiz3l1_e5ji-rWoqlc/){target="_blank"}.
    + **If you need a group**: Please fill out this [Google Form](https://docs.google.com/forms/d/e/1FAIpQLSeifexbjkXQNgm6d7bvSn0KcYoB6RVH5ab50o-RS6NfAS58AQ/viewform) and I'll assign one for you.


## Working on your project {#MP2-working}

* Join the `#mp2` Slack channel.
* Download the `MP2.zip` archive file containing the MP2 RStudio Project by clicking <a href="static/MP2.zip" download>here</a>.
* **Windows users**: Be sure to "extract" the contents of `MP2.zip` to a folder on your machine.
* Whenever working on MP2, be sure to be in "RStudio Project mode" either by:
    1. Clicking the `MP2.Rproj` file
    1. Selecting `MP2` from the drop-down menu of RStudio Projects in the top right of RStudio.
* Knit the `MP2.Rmd` file and read over everything once.
* Whenever you're not working on your project, click the RStudio Project icon in the top right of RStudio and select "Close Project".
* Policies:
    + You may use a function from a package to compute the RMLSE.
    + You may not use a function from a packge to perform cross-validation; please code it up manually.
    + Feel free to use external sources, but please cite them using R Markdown footnotes. For example adding `^[This is my [source](https://www.smith.edu/)]` at the end of a sentence in R Markdown will yield: ^[This is my [source](https://www.smith.edu/)]
* **Clarifications added Friday 3/1 5PM**:
    + From the "Minimally viable product" phase, you can remove the `## Comparisons of estimated scores and Kaggle scores` subsection, as this is part of the following "Due diligence" phase
    + From the "Due diligence" phase, you can remove the `## Model fitting`, `## Estimate of your Kaggle score`, `## Create your submission CSV`, and `## Screenshot of your Kaggle score` subsections, as those were part of the previous "Minimally viable product" phase.
* **Clarifications added Tuesday 3/5 8AM**:
    + For the "point of diminishing returns" phase asking you to use a "subset selection" method from Chapter 6.1, don't start with all 81 predictor variables, but rather start with only the 6 variables from the "reaching for the stars" phase. Think of it this way: you are "shopping" for variables to include in your model and want to pick the "best" ones to put in your shopping cart (your ultimate model). Your choice of variables to "shop from" are not ALL 81 predictors, since it would take forever to do an exploratory data analysis, clean, and make sure all variables work in a fitted model. Rather your choice of variables to "shop from" are the 6 predictors from the "reaching for the stars" phase, since you already did an exploratory data analysis on, cleaned, and made sure all variables work in a fitted model. So after applying a subset selection method, you'll end up with a model with either 0, 1, ..., 5, or 6 of your "reaching for the stars" variables.  
    **Why are we doing this?**  Later on, we'll study an even MORE principled way to "shop" for variables than "subset selection" called LASSO regularization. For a preview see Chapter 6.2.2. in the ISLR textbook.
    + For all three models $\widehat{f}_{1}$, $\widehat{f}_{2}$, $\widehat{f}_{3}$, your estimate of $\widehat{\text{RMLSE}}$ **must** closely match the $\text{RMLSE}$ that Kaggle returns; the grader will be instructed to grade accordingly. By "closely match" it is generally meant that they must be of the same [order of magnitude](https://en.wikipedia.org/wiki/Order_of_magnitude){target="_blank"}.  
    **Why are we doing this?** Because in an active Kaggle competition, you are almost always limited in the number of submissions you can make in a day. For example, in the currently running [Google Analytics Customer Revenue Prediction](https://www.kaggle.com/c/ga-customer-revenue-prediction/rules){target="_blank"} competition, you can only make 5 submissions a day, hence only get 5 scores a day. If you're serious about winning a competition however, you'll definitely need to evaluate more than 5 models a day. So if you are limited in the number of "real" $\text{RMLSE}$ scores you can obtain in a day, what is the next best thing? Getting *estimates* of the score $\widehat{\text{RMLSE}}$.
    + You are not required to explicitly submit any exploratory visualizations for this MP. However you should still be making visualizations during your model fitting phase, just not invest the time to polish them. That being said, including a well polished visualization that argues why a particular predictor variable should be used can be a very effective way to provide insight and hence make your report stand out. 
    + What is meant by "remove all superfluous non-informative output"? Think of it this way: If two people present two R Markdown reports containing roughly the same amount of new insight and information, but one is 2 pages long and one is 20 pages long, which one do you think people will read? The answer is obvious. However, what precisely constitutes "non-informative output" is often a subjective and non-obvious choice. Whatever your choice may be however, you'll need to **own that choice**. That being said, one example of obviously "non-informative output" is including the entire contents of a 10k row data frame in your report; no human on earth can digest 10k rows of data.
* **Hints added Tuesday 3/5 8AM**:
    + Crossvalidation does one thing and one thing only: it returns an estimate $\widehat{\text{RMLSE}}$ of the true $\text{RMLSE}$ when you don't have access to the $y$'s in the test set. But unlike the "validation set" approach, every observation gets predicted once, in other words every $y$ gets a turn at being predicted with a $\widehat{y}$. Now, what you do with these estimates $\widehat{\text{RMLSE}}$ is another question. So for example in MP1, we used these estimates $\widehat{\text{RMLSE}}$ to choose the optimal complexity of the splines model as determined by the optimal $df^*$; but choosing the optimal complexity of a model is not *inherently* part of crossvalidation; it merely *uses* the results of crossvalidation.
    + *"Help! I'm having a lot of trouble working with categorical variables!"* Good! That is the point of this MP! When you're encountering such issues, start peeling away all the layers of abstraction and **look at your data**. Go inside the inputs and outputs of functions and `for` loops and look at the raw values, compute summary statistics, and create visualizations. You'll almost always find the source of your error/issue somewhere in the data.
    + **Start simple and build up, don't start complex and build down!** Compare these two approaches:
        1. You fit a model using predictors $x_1, x_2$ and it returns working predictions $\widehat{y}$. You fit the next iteration of the model using $x_1, x_2, x_3$ but get an error. What is the source of the problem?
        1. You fit a model using **all** predictors $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}, x_{6}, x_{7}, x_{8}, x_{9}, x_{10}, x_{11}, x_{12}, x_{13}, x_{14}, x_{15}, x_{16}, x_{17}, x_{18}, x_{19}, x_{20}, x_{21}, x_{22}, x_{23}, x_{24}, x_{25}, x_{26},$  
        $x_{27}, x_{28}, x_{29}, x_{30}, x_{31}, x_{32}, x_{33}, x_{34}, x_{35}, x_{36}, x_{37}, x_{38}, x_{39}, x_{40}, x_{41}, x_{42}, x_{43}, x_{44}, x_{45}, x_{46}, x_{47}, x_{48}, x_{49}, x_{50},$  
        $x_{51}, x_{52}, x_{53}, x_{54}, x_{55}, x_{56}, x_{57}, x_{58}, x_{59}, x_{60}, x_{61}, x_{62}, x_{63}, x_{64}, x_{65}, x_{66}, x_{67}, x_{68}, x_{69}, x_{70}, x_{71}, x_{72}, x_{73}, x_{74},$   
        $x_{75}, x_{76}, x_{77}, x_{78}, x_{79}, x_{80}, x_{81}$  
        but get an error. What is the source of the problem?


<!--
library(tidyverse); str_c("x_{", 1:81, "}", sep = "") %>% str_c(collapse = ", ")
-->

## What to submit

* **Group leader only**: Submit a `MP2_Group_XX.zip` archive file of **all** the contents of your `MP2` RStudio Project folder.  
* **Both group members**: Complete the following peer evaluation [Google Form](https://docs.google.com/forms/d/e/1FAIpQLSf0a9F3_tZNtil3_IZBwPpvxuC2ubmWs54fDuFmmxYtcrhN-w/viewform){target="_blank"}.  
Both group members must complete the Google Form to receive full credit.


## Grading

1. **Baseline:** Projects that do not satisfy all "baseline" criteria should expect to get a grade of less than 8/10.
    + Your `MP2.Rmd` R Markdown file must absolutely "knit" correctly. 
    + Regardless of which model you fit, you must output a submission `.csv` file that returns a valid $\text{RMLSE}$ score on Kaggle. The grader will test this.
    + All plots (if any) must be "stand-alone" as possible by having informative labels and titles. 
    + Remove all superfluous non-informative output from your report that only makes it more painful/tiresome to read.
    + Both group members submit their peer evaluations. No extensions will be granted.
1. **Minimally viable product:** Grade: 8/10.
    + Satisfy all "baseline" criteria.
    + Fit a regression model $\widehat{f}_{1}$ using one arbitrarily chosen numerical predictor and one arbitrarily chosen categorical predictor.
1. **Due diligence:** Grade: 8.5/10.
    + Satisfy all "baseline" and "minimally viable product" criteria.
    + Using the model $\widehat{f}_{1}$, obtain an estimate $\widehat{\text{RMLSE}}$ that closely matches the $\text{RMLSE}$ that Kaggle returns.
1. **Reaching for the stars:** Grade: 9/10. 
    + Satisfy all "baseline", "minimally viable product", and "due diligence" criteria.
    + Fit a regression model $\widehat{f}_{2}$ using **three** arbitrarily chosen numerical predictors and **three** arbitrarily chosen categorical predictors.
    + Using this model $\widehat{f}_{2}$, obtain an estimate $\widehat{\text{RMLSE}}$ that closely matches the $\text{RMLSE}$ that Kaggle returns.
    + Compare the $\widehat{\text{RMLSE}}$ and $\text{RMLSE}$ you obtain for $\widehat{f}_{2}$ with the ones you obtained with $\widehat{f}_{1}$. 
1. **Point of diminishing returns:** Grade: 9.5/10.
    + Satisfy all "baseline", "minimally viable product", "due diligence", and "reaching for the stars" criteria.
    + Fit a regression model $\widehat{f}_{3}$ choosing your predictor variables **from the 6 your chose in the "reaching for the stars" phase** in a non-arbitrary fashion using a method in Chapter 6.1 of the ISLR textbook.
    + Using this model $\widehat{f}_{3}$, obtain an estimate $\widehat{\text{RMLSE}}$ that closely matches the $\text{RMLSE}$ that Kaggle returns.  
    + Compare the $\widehat{\text{RMLSE}}$ and $\text{RMLSE}$ you obtain for all three models $\widehat{f}_{1}$, $\widehat{f}_{2}$, and $\widehat{f}_{3}$
1. **Polishing the cannonball:** Grade: 10/10.
    + Satisfy all "baseline", "minimally viable product", "due diligence", "reaching for the stars", and "point of diminishing returns" criteria.
    + Try to get the highest Kaggle score in the class!


## Suggestions

* Start simple and slowly add complexity. If you start with the most complex model possible and something doesn't work, you'll have a harder time debugging.
* In other words, add variables incrementally and build up your models. Don't start with everything and build down to a working model.


***



# Mini-project 3 {#MP3}

## Administrative notes



## Administrative notes

* **Executive summary**: You will be making a submission to the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques){target="_blank"} Kaggle competition based on a fitted ~~spline~~ multiple regression model. The competition's score for leaderboard purposes is the "root mean squared logarithmic error" (RMSLE).
* **Due Wednesday 3/27 5pm on Moodle**. 
* You will be given time to work on MP3 in class on Monday 3/25 and Wednesday 3/27.
* Groups: Posted on [Moodle](https://moodle.smith.edu/course/view.php?id=33108){target="_blank"}. Whoever member \#1 is will be the group leader.  
Ex: Group \#1's leader is LQ.




***



# Mini-project 4 {#MP4}

## Administrative notes

* **Due Wednesday 4/17 5pm on Moodle**. 


***


# Mini-project 5 {#MP5}

## Administrative notes

* **Due Thursday 5/2 5pm on Moodle**. 



***




<!--

*Assigned Tue 1/29, due Tue 2/5 at XXXpm Eastern Time*


# Problem set 12 {#PS12}

*Final problem set of the year! Assigned Wednesday 12/5, due Wednesday 12/12 at 1pm Eastern Time. Quiz at the end of lecture on Wednesday 12/12.*


## 1. R component {#PS12_R}

* Before starting PS12:
    + Read the solutions to PS11
    + Read ModernDive 9.2-9.4.
* Download the following <a href="static/PS/PS12_lastname_firstname.Rmd" download>Rmd template</a> file and rename the file appropriately. **Note: A new version of the R Markdown file with two typos corrected was posted on Thu 12/6 at 3:30PM.**
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 

## 2. Quiz II

* Watch the
    + 3m38s Video 1 below (also in ModernDive 8.5) on bunny rabbits, dragons, and the Central Limit Theorem.
    + 4m41s Video 2 below on permutation hypothesis tests.
* At the end of lecture on Wednesday 12/12 you will be given a 10-15 minute quiz. This quiz is not meant to be difficult; it is meant simply to ensure that you watch and understand both videos.
* No make-up quizzes without official permission Ex: Dean's note. 

### Video 1

<iframe width="560" height="315" src="https://www.youtube.com/embed/jvoxEYmQHNM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Video 2

<iframe width="560" height="315" src="https://www.youtube.com/embed/2pHhjx9hyM4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## 3. R solutions & (imperfect) rubric

* <a href="static/PS/PS12_solutions.Rmd" download>`PS12_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS12_solutions.html`](static/PS/PS12_solutions.html){target="_blank"} output.

**(Imperfect) rubric**: 

13 pts total

* Question 1: 2 pts
* Question 2: 2 + 3 + 6 pts



***




# Problem set 11 {#PS11}

*Assigned Wednesday 11/28, due Wednesday 12/5 at 1pm Eastern Time*

## 1. R component {#PS11_R}

* Before starting PS11:
    + Read the solutions to PS10
    + Read ModernDive 9.2-9.4.
* Download the following <a href="static/PS/PS11_lastname_firstname.Rmd" download>Rmd template</a> file and rename the file appropriately.
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 



## 2. R solutions & (imperfect) rubric {#PS11_R_solutions}

* <a href="static/PS/PS11_solutions.Rmd" download>`PS11_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS11_solutions.html`](static/PS/PS11_solutions.html){target="_blank"} output.


**(Imperfect) rubric**: 

13 pts total

* Question 1: 2 pts
* Question 2: 2 + 3 + 6 pts



***



# Problem set 10 {#PS10}

*Assigned Wednesday 11/14, due Wednesday 11/28 at 1pm Eastern Time*

## 1. R component {#PS10_R}

* Before starting PS10:
    + Re-read your notes from Lec24 and ModernDive 8.1 to make sure you understand all the definitions and notation. In particular:
    + Note you don't need the "bootstrap resampling with replacement" topic we started with our tactile exercise on the mean height of the class in Lec28. 
* Download the following <a href="static/PS/PS10_lastname_firstname.Rmd" download>Rmd template</a> file and rename the file appropriately.
* R Markdown Knitting strategies:
    + Knit the `PS10_lastname_firstname.Rmd` file once and read all the questions.
    + Knit early, knit often! This will help pinpoint errors as they happen.
    + If you get stuck, **go through these [6 R Markdown Fixes](https://docs.google.com/document/d/1P7IyZ4On9OlrCOhygFxjC7XhQqyw8OludwChz-uFd_o/){target="_blank"} first**, then seek assistance. These 6 fixes resolve 85% of issues in my experience.
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.

## 2. R solutions & (imperfect) rubric {#PS10_R_solutions}

* <a href="static/PS/PS10_solutions.Rmd" download>`PS10_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS10_solutions.html`](static/PS/PS10_solutions.html){target="_blank"} output.

**(Imperfect) rubric**: 

22 pts total

* Question 1: 1 + 1 + 2 + 2 pts
* Question 2: 1 + 1 + 2 + 2 pts
* Question 3: 2 pts
* Question 4: 1 + 1 + 1 + 3 + 2 pts



***



# Problem set 9 {#PS09}

**Note that I am posting this PS ahead of schedule. PS08 is below and is due Wed 11/7 1pm.**

*Assigned Wednesday 11/7, quiz at the end of lecture on Wednesday 11/7.*

## 1. Quiz I

<center>
<img src="static/images/hang_the_dj.png" alt="Drawing" style="width: 400px;"/>
</center>
<br>

* Watch Netflix -> Black Mirror -> Season 4 -> Episode 4 "Hang the DJ" (51 min). You will need access to Netflix:
    + If you do not have access to Netflix and you have access to a credit card, you can get a free 1-month trial. Be sure to cancel your account after you watch the episode.
    + **If you do not have access to Netflix and you don't have access to a credit card, please Slack me ASAP.** 
* If you are uncomfortable watching sexually explicit scenes and would rather skip them, they occur at:
    1. 15:10 - 16:32
    1. 22:02 - 22:29
    1. 24:46 - 24:53
    1. 42:19 - 43:09
* At the end of lecture on Wednesday 11/14 you will be given a 2 question, 5 minute quiz. This quiz is not meant to be difficult; it is meant simply to ensure that you watch **all** 51 minutes and pay attention.
* No make-up quizzes without official permission Ex: Dean's note. 



***



# Problem set 8 {#PS08}

*Assigned Wednesday 10/31, due Wednesday 11/7 at 1pm Eastern Time*

## 1. R component {#PS08_R}

* Before starting PS08:
    + Re-read the `PS07_solutions.Rmd` solutions posted. 
    + Make sure you've updated the `moderndive` package, but this time not from the R package app store that you normally install packages from, but from GitHub. See Lec22 for instructions on how to do so. If you get stuck, please speak to me or Jenny.
* Download the following <a href="static/PS/PS08_lastname_firstname.Rmd" download>Rmd template</a> file and rename the file appropriately.
* R Markdown Knitting strategies:
    + Knit the `PS08_lastname_firstname.Rmd` file once and read all the questions.
    + Knit early, knit often! This will help pinpoint errors as they happen.
    + If you get stuck, **go through these [6 R Markdown Fixes](https://docs.google.com/document/d/1P7IyZ4On9OlrCOhygFxjC7XhQqyw8OludwChz-uFd_o/){target="_blank"} first**, then seek assistance. These 6 fixes resolve 85% of issues in my experience.
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.

## 2. R solutions & (imperfect) rubric {#PS08_R_solutions}

* <a href="static/PS/PS08_solutions.Rmd" download>`PS08_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS08_solutions.html`](static/PS/PS08_solutions.html){target="_blank"} output.

**(Imperfect) rubric**: 

10 pts total

* Question 1: 9 pts = 1 + 1 + 2 + 3 + 2
* Putting informative axes labels and titles for all plots: 1 pt
* Extra-credit: 1 pt



***



# Problem set 7 {#PS07}

*Assigned Wednesday 10/24, due Wednesday 10/31 at 1pm Eastern Time*

No DataCamp nor written component.

## 1. R component {#PS07_R}

* Before starting PS07:
    + Re-read the `PS02_solutions.R` solutions posted below under PS02. 
* Download the following <a href="static/PS/PS07_lastname_firstname.Rmd" download>Rmd template</a> file and rename the file appropriately.
* R Markdown Knitting strategies:
    + Knit the `PS07_lastname_firstname.Rmd` file once and read all the questions.
    + Knit early, knit often! This will help pinpoint errors as they happen.
    + If you get stuck, **go through these [6 R Markdown Fixes](https://docs.google.com/document/d/1P7IyZ4On9OlrCOhygFxjC7XhQqyw8OludwChz-uFd_o/){target="_blank"} first**, then seek assistance. These 6 fixes resolve 85% of issues in my experience.
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.


## 2. R solutions & (imperfect) rubric {#PS07_R_solutions}

* <a href="static/PS/PS07_solutions.Rmd" download>`PS07_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS07_solutions.html`](static/PS/PS07_solutions.html){target="_blank"} output.

**(Imperfect) rubric**: 

22 pts total

* Question 1: 12 pts = 2 + 7 + 3
* Question 2: 9 pts = 1 + 1 + 2 + 3 + 2
* Something extra or exceptional: 1 pt



***




# Problem set 6 {#PS06}

*Assigned Wednesday 10/17, due Wednesday 10/24 at 1pm Eastern Time*

## 1. DataCamp

None.

## 2. R component {#PS06_R}

* Before starting PS06:
    + Read ModernDive 6.1.4
    + Download, knit, and read the `PS05_solutions.Rmd` solutions posted below under PS05. 
* Download the following <a href="static/PS/PS06_lastname_firstname.Rmd" download>Rmd template</a> file and rename the file appropriately.
* R Markdown Knitting strategies:
    + Knit the `PS06_lastname_firstname.Rmd` file once and read all the questions.
    + Knit early, knit often! This will help pinpoint errors as they happen.
    + If you get stuck, **go through these [6 R Markdown Fixes](https://docs.google.com/document/d/1P7IyZ4On9OlrCOhygFxjC7XhQqyw8OludwChz-uFd_o/){target="_blank"} first**, then seek assistance. These 6 fixes resolve 85% of issues in my experience.
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.


## 3. Written component

* In [OpenIntro: Intro Stat with Randomization and Simulation](https://www.openintro.org/stat/textbook.php?stat_book=isrs){target="_blank"} (click on Tablet-friendly PDF):
    + Look at the plot in Exercise 5.11 on the Coast Starlight on book page 248 (which is on the page number 254 of the PDF).
    + Do the following portions of Exercise 5.19 on book page 252 (which is on page number 258 of the PDF):
        a) Skip this. The slope of the regression line is 0.726 whereas the intercept is 51.
        a) Do this.
        a) Skip this.
        a) Do this.
        a) Do this.
        a) Do this.
* **New**: See [syllabus](syllabus.html#evaluation-expectations) for expectations on written component submissions.


## 4. R solutions & (imperfect) rubric {#PS06_R_solutions}

* <a href="static/PS/PS06_solutions.Rmd" download>`PS06_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS06_solutions.html`](static/PS/PS06_solutions.html){target="_blank"} output.
* [Written solutions](static/PS/PS06_solutions.png){target="_blank"}


**(Imperfect) rubric**: A more straightforward problem set with little to no "story" to tell nor subjectivity. 

* Rmd component: 1 + 2 + 1 + 1 + 1 + 1 = 7 pts. 
* Written component: 2 + 1 + 2 + 1 = 6 pts


***


# Problem set 5 {#PS05}

*Assigned Wednesday 10/10, due Wednesday 10/17 at 1pm Eastern Time*

## 1. DataCamp

* Complete the following two chapters from the "Modeling with Data in the Tidyverse" course, which you should see [here](https://www.datacamp.com/courses/modeling-with-data-in-the-tidyverse){target="_blank"}.
    + Chapter 3: Modeling with Multiple Regression
    + Chapter 4: Model Assessment and Selection. Do not forget the conclusion video.
* See the [syllabus](syllabus.html#evaluation-expectations) for expectations on DataCamp assignments.


## 2. R Markdown component {#PS05_R}

* Download the following Rmd template file: <a href="static/PS/PS05_lastname_firstname.Rmd" download>`PS05_lastname_firstname.Rmd`</a> and rename it appropriately.
* R Markdown Knitting strategies:
    + Knit the `PS05_lastname_firstname.Rmd` file once and read all the questions.
    + Knit early, knit often! This will help pinpoint errors as they happen.
    + If you get stuck, **go through these [6 R Markdown Fixes](https://docs.google.com/document/d/1P7IyZ4On9OlrCOhygFxjC7XhQqyw8OludwChz-uFd_o/){target="_blank"} first**, then seek assistance. These 6 fixes resolve 85% of issues in my experience.
* Submission: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.
* **Hints** on Question 2 on Dunkin Donuts vs Starbucks.
    + You will need to use `dplyr` "Data Wrangling" verbs to both get the data ready for modeling and to address the "in units of \$10K = \$10,000" question. See the summary table of verbs in ModernDive Chapter 5.10 on Data Wrangling.
    + This question is a tricky one, however it can be viewed as a "mini practice final project" as it combines many elements of the data/science pipeline to "tell a story with data."
    
<center>
![](static/images/pipeline.png){ width=600px }
<center>



## 3. R Markdown solutions & (imperfect) rubric {#PS05_R_solutions}

* <a href="static/PS/PS05_solutions.Rmd" download>`PS05_solutions.Rmd`</a> "source code" to create html report output. 
* Resulting [`PS05_solutions.html`](static/PS/PS05_solutions.html){target="_blank"} output.
* Link to all code from "Working with Data in the tidyverse" DataCamp course can be found at [http://bit.ly/modeling_tidyverse](http://bit.ly/modeling_tidyverse){target="_blank"}

**(Imperfect) rubric**:

Total 11 pts.

* Question 1: 7 pts
    + LC 6.1: 1 pt if each code block is correct
    + LC 6.2: 1 pt if each code block is correct, 1 pt for each interpretation question
* Question 2: 3 pts
    + 2 pt for data wrangling
    + 1 pt for solution
* Something extra or exceptional: 1pt


***


# Problem set 4 {#PS04}

*Assigned Wednesday 10/3, due Wednesday 10/10 at 1pm Eastern Time*

## 1. DataCamp

* Complete the following two chapters from the "Modeling with Data in the Tidyverse" course, which you should see [here](https://www.datacamp.com/courses/modeling-with-data-in-the-tidyverse){target="_blank"}.
    + Chapter 1: Introduction to Modeling
    + Chapter 2: Modeling with Basic Regression
* See the [syllabus](syllabus.html#evaluation-expectations) for expectations on DataCamp assignments.


## 2. R component {#PS04_R}

You'll be analyzing the results of the Africa survey experiment we did in Lecture 2 and data from the Titanic disaster.

* Download the following R scratchpad: <a href="static/PS/PS04_lastname_firstname.R" download>`PS04_lastname_firstname.R`</a> and rename it so that it matches your name. For example in my case: `PS04_Kim_Albert.R`. **Note on 10/4**: Question 2.b) originally read  `b) Survival split by class`. It should read `b) Survival split by sex`. This has been updated in the `PS04_lastname_first.R` file.
* Open `PS04_lastname_firstname.R` and follow the indicated steps. I *highly* recommend you copy and paste existing code from ModernDive and then tweak it to achieve your goal.
* When you are finished, check that your code is *reproducible and replicable*. Meaning if you were to send someone else this file and they ran the code, woult they get the same results as you?
    + Save your work. The filename `PS04_lastname_firstname.R` should change from red to black.
    + Close `PS04_lastname_firstname.R`.
    + Restart R: RStudio menu bar -> Session -> Restart R. This "reboots R" by deleting all previously saved data frames and shuts down all loaded packages.
    + Go to the Files panel of RStudio and re-open `PS04_lastname_firstname.R`.
    + Re-run all your code to make sure that you can replicate all results. 
* **Submission**: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.

**Hints**:

* Write out "pseudocode" of your data wrangling steps **first** and then start coding (See Tweet of the day for Lec12). This will help you from confusing *what* you are trying to do and *how* am I going to code it.


## 3. R solutions & (imperfect) rubric {#PS04_R_solutions}

Download <a href="static/PS/PS04_solutions.R" download>`PS04_solutions.R`</a>.

**(Imperfect) rubric**:

Total 10 pts.

* Question 1: 6 pts
* Question 2: 3 pts
* Something extra or exceptional: 1pt


***


# Problem set 3 {#PS03}

*Assigned Wednesday 9/26, due Wednesday 10/3 at 1pm Eastern Time*

## 1. DataCamp

No DataCamp this week.


## 2. R component {#PS03_R}

Read the following Chance Magazine article [Looking Good on Course Evaluations](http://chance.amstat.org/2013/04/looking-good/){target="_blank"} up to and including Table 1. In particular, note the introductory paragraph:

> At the end of each semester, students provide feedback on their courses via anonymous course evaluations. However, use of student evaluations as indicators of quality of the course and teaching effectiveness is often criticized since these measures may be reflecting biases in favor of nonteaching-related characteristics, such as the physical appearance of the instructor.

You'll be analyzing the same data used in this study. The data is in the `evals` data frame, which is included in the `moderndive` R package. A larger goal of this problem set is to start practicing answering questions with data visualizations

* Download the following R scratchpad: <a href="static/PS/PS03_lastname_firstname.R" download>`PS03_lastname_firstname.R`</a> and rename it so that it matches your name. For example in my case: `PS03_Kim_Albert.R`.
* Open `PS03_lastname_firstname.R` and follow the indicated steps. I *highly* recommend you copy and paste existing code from ModernDive and then tweak it to achieve your goal.
* When you are finished, check that your code is *reproducible and replicable*. Meaning if you were to send someone else this file and they ran the code, woult they get the same results as you?
    + Save your work. The filename `PS03_lastname_firstname.R` should change from red to black.
    + Close `PS03_lastname_firstname.R`.
    + Restart R: RStudio menu bar -> Session -> Restart R. This "reboots R" by deleting all previously saved data frames and shuts down all loaded packages.
    + Go to the Files panel of RStudio and re-open `PS03_lastname_firstname.R`.
    + Re-run all your code to make sure that you can replicate all images.
* **Submission**: Submit this on [Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.

**Hints**:

* Everything you need to know for this problem set are based on Lectures 1-7 in particular the ModernDive readings.
* While I encourage you collaborate/help each other out, please make an honest effort to do this problem set. This is practice for the final project.


## 3. R solutions & (imperfect) rubric {#PS03_R_solutions}

Download <a href="static/PS/PS03_solutions.R" download>`PS03_solutions.R`</a>.

**(Imperfect) rubric**:

* 8/10 or lower: If any of the plots were off.
* 9/10: If all 5 plots work. **Most students got 9/10**.
* 10/10: If all 5 plots work something "extra" or "exceptional". For example, in Q2.c), someone did a comparison of the "story" that boxplots vs facetted histograms tell. 


***


# Problem set 2 {#PS02}

*Assigned Wednesday 9/19, due Wednesday 9/26 at 1pm Eastern Time*


## 1. DataCamp

* Complete the "Introduction to the Tidyverse" course, which you should see [here](https://www.datacamp.com/courses/introduction-to-the-tidyverse){target="_blank"}.
* Note: DataCamp does things in a slightly order, data wrangling first then data visualization. ModernDive however does data visualization first in Chapter 3 then data wrangling in Chapter 5. Reading ModernDive Chapter 5 is not a pre-requisite for completing this problem set.
* See the [syllabus](syllabus.html#evaluation-expectations) for expectations on DataCamp assignments.
* If you have already completed the "Introduction to the Tidyverse" DataCamp course previously using a DataCamp account based on your Smith email, you do not need to re-do them; they will show up in my logs as completed.


## 2. R component {#PS02_R}

Read the following 538 article [Higher Rates Of Hate Crimes Are Tied To Income Inequality](https://fivethirtyeight.com/features/higher-rates-of-hate-crimes-are-tied-to-income-inequality/){target="_blank"}. You'll be analyzing the same data used to write this article. The data is in the `hate_crimes` dataframe, which is included in the `fivethirtyeight` R package. A larger goal of this problem set is to start practicing the "data analysis" workflow.

* Download the following R scratchpad: <a href="static/PS/PS02_lastname_firstname.R" download>`PS02_lastname_firstname.R`</a> and rename it so that it matches your name. For example in my case: `PS02_Kim_Albert.R`.
* "Upload" this file to RStudio Server by going to RStudio -> Files panel -> Upload.
* Open `PS02_lastname_firstname.R` and follow the indicated steps. I *highly* recommend you copy and paste existing code from ModernDive and then tweak it to achieve your goal.
* When you are finished, check that your code is *reproducible and replicable*. Meaning if you were to send someone else this file and they ran the code, woult they get the same results as you?
    + Save your work and close `PS02_lastname_firstname.R`.
    + Restart R: RStudio menu bar -> Session -> Restart R. This "reboots R" by deleting all previously saved data frames and shuts down all loaded packages.
    + Go to the Files panel of RStudio and re-open `PS02_lastname_firstname.R`.
    + Run all your code as described in [Lec4](#Lec04) and make sure that you can replicate the scatterplot.
* **Submission**: ~~Download this file on to your compter by going to RStudio -> Files panel -> More -> Export.~~  (9/20 10am update: I just crossed out the outdated instructions assuming you were working on RStudio Server. Since we are now assuming RStudio Desktop, the `PS02_lastname_firstname.R` file should exist on your computer) Submit this`PS02_lastname_firstname.R`[Moodle](https://moodle.smith.edu/course/view.php?id=30498){target="_blank"}. 
* See [syllabus](syllabus.html#evaluation-expectations) for expectations on R component submissions.

**Hints**:

* Everything you need to know for this problem set are based on Lectures 1-4, in particular the ModernDive readings.
* While I encourage you collaborate/help each other out, please make an honest effort to do this problem set. Part of the graders' and my goal in grading the problem sets is to identify both your **strengths and weaknesses** in preparation for the projects. Don't forget the lowest two problem set scores are dropped!


## 3. R solutions & (imperfect) rubric {#PS02_R_solutions}

Download <a href="static/PS/PS02_solutions.R" download>`PS02_solutions.R`</a>.

**(Imperfect) rubric**:

* 8/10 or lower: If something didn't work. Example: submitted a blank file or code doesn't run.
* 9/10: If you did everything as asked. Example: Make a working plot using the correct variable `avg_hatecrimes_per_100k_fbi` on the y-axis. **Most students got 9/10**.
* 10/10: The extra point was for doing something "extra" or "exceptional". Example: added labels to axes to plot or anything to make it more interpretable.
* Each point is roughly worth 0.23% of final grade (this is not accounting for fact that lowest two problem set grades are dropped).


***


# Problem set 1 {#PS01}

*Assigned Wednesday 9/12, due Wednesday 9/19 at 1pm Eastern Time*

1. **DataCamp**
    * Complete the following chapters from the "Introduction to R" course, which you should see in the following [link](https://www.datacamp.com/enterprise/2018-09-sds220-intro-to-probability-statistics/assignments){target="_blank"}:
        * Chapter 1: "Intro to basics"
        * Chapter 2: "Vectors"
        * Chapter 4: "Factors"
        * Chapter 5: "Data Frames"
    * Expectations about DataCamp assignments have been posted in the [syllabus](syllabus.html#datacamp)
1. **Administrative stuff**: To receive full credit for this portion simply ensure
    * Slack:
        1. Your full name is listed: full name = how you would like to be addressed in class & last name.  
        1. You have added a profile picture with your face visible. This will help me learn your names.
        1. Hint: Start relying on Google! "How do I change my name and profile picture on Slack?"
        1. You are a member of the `#moderndive_typoes`, `#r_questions`, and `random` channels.
    * DataCamp: Your full name is listed in your [profile](https://www.datacamp.com/profile/account_settings){target="_blank"}; the rest is optional.



-->

