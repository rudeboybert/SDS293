---
title: "Midterms"
output:
  html_document:
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE, 
                      cache=TRUE, fig.width=16/2, fig.height=9/2)
# Set seed value of random number generator to get "replicable" random numbers.
# Why 76? Because of https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

<style>
h1{font-weight: 400;}
</style>



***



# Midterm I {#midtermI}

## Administrative notes

* **Friday 2/22 5pm through Sunday 2/24 11:55pm**.
* Self-scheduled exam [instructions](http://www.science.smith.edu/self-scheduled-exam-printing/){target="_blank"}. In particular:
    + Only print from macOS computers.
    + At some point you'll need to wait 5-10 seconds for a "paper is held in queue" pop-up box to appear before you can print.
* You will be given 140 mins to complete it (including transit time to writing area), however I try to time it so that it will take much less than that. In other words, you should have plenty of time to complete it without rushing.
* **Timestamps will be strictly enforced. Any timestamps indicating than more than 140 minutes are subject to a 50% penalty and an honor board case.**
* Closed-book, no internet, and individually completed.


## Topics
    
* Topics: All topics covered so far, but not regression.
* What to study:
    + Lec01 Slides: A minimally-viable explanation of machine learning in 60min.
    + General modeling framework: $y = f(\vec{x}) + \epsilon$ vs $\hat{y} = \hat{f}(\vec{x})$ .See "Modeling with data in the tidyverse" DataCamp Chapter 1 videos for more info.
    + Machine learning problem: underfitting/overfitting, measures of model complexity, training/test set splitting, cross-validation.
    + Splines: describe qualitatively how model is fit.
    + Class chalk talk notes
    + `MP1_albert.Rmd`
* No direct coding, but you will have to write pseudocode.




***



# Midterm II {#midtermII}

## Administrative notes

* **Friday 4/5 5pm through Sunday 4/7 11:55pm**. 
* Self-scheduled exam [instructions](http://www.science.smith.edu/self-scheduled-exam-printing/){target="_blank"}. In particular:
    + Only print from macOS computers.
    + At some point you'll need to wait 5-10 seconds for a "paper is held in queue" pop-up box to appear before you can print.
* You will be given 140 mins to complete it (including transit time to writing area), however I try to time it so that it will take much less than that. In other words, you should have plenty of time to complete it without rushing.
* **Timestamps will be strictly enforced. Any timestamps indicating than more than 140 minutes are subject to a 50% penalty and an honor board case.**
* Closed-book, no internet, and individually completed.


## Topics
    
* Topics: 
    + Not commulative, so no direct questions from Midterm I. That being said, the material builds, so you still need to understand
        + the general modeling framework: $y = f(\vec{x}) + \epsilon$ vs $\hat{y} = \hat{f}(\vec{x})$
        + the machine learning problem: underfitting/overfitting, measures of model complexity, training/test set splitting, cross-validation.
    + New topics: Lectures 05 through 16
        + Multiple regression
        + Logistic regression
        + Understanding contingency tables + ROC/AUC. You do not need to memorize the formulas, but understand how they are constructed and interpret their meaning.
        + CART. Questions on CART will not be as deep since we have not had a MP on this yet.
* What to study:
    + Chalk talk notes
    + Any exercises in class in the [Code](code.html) portion of webpage. Note while there is no direct coding, but you will have to write pseudocode.
    + All Shiny apps
    + No direct questions from associated readings in ISLR. Please read these only if you don't understand something from class.
    + `MP3.Rmd` solutions



## Question 3 resubmission instructions {#revise}

You can revise and resubmit **only Question 3** for ~~half~~ ALL points back if you do the following:

* Re-do Question 3 and answer all elements of the question **correctly**.
* Write in pseudocode, no code. What is pseudocode?
    + First off, it is not language specific. R and python programmers should be able to understand.
    + It explicit. Imagine someone is an expert coder, but doesn't understand machine learning. Take should take your "pseudocode recipe" and be able to implement the algorithm.
    + A good guide is: think of pseudocode as what you would comment your code with.
* In addition answer the following question: Given an outcome variable $y$, a corresponding "score" (i.e. scoring mechanism that measures prediction quality, like RMSE, RMLSE, AUC, classification accuracy, etc.), and `training` and `test` sets (not necessarily as part of a Kaggle competition), cross-validation returns one value. What is this value? Answer in **one** sentence. 
* Staple your resubmission to the back of your midterm and submit it no later than the end of next Monday's lecture.    
* You may consult your peers.

